# Core Implementation Rules

## Audio Processing

```python
# Device setup
device_info = audio.get_device_info_by_index(device_id)
sample_rate = int(device_info["defaultSampleRate"])
buffer_size = chunk_size * 4

# Shutdown sequence
self._stop_requested = True
while stream.is_active() and stream.get_read_available() > 0:
    data = stream.read(chunk_size, exception_on_overflow=False)
stream.stop_stream()
stream.close()

# Audio processing
audio_data = np.frombuffer(chunk, dtype=np.float32)
audio_data = audio_data / np.max(np.abs(audio_data))
resampled = signal.resample(audio_data, target_length)
```

## ElevenLabs Integration

```python
async def synthesize(self, text: str) -> bytes:
    url = f"{API_BASE}/text-to-speech/{voice_id}/stream"
    headers = {"Accept": "application/json", "xi-api-key": api_key}
    data = {
        "text": text,
        "model_id": model_id,
        "voice_settings": {
            "stability": stability,
            "similarity_boost": similarity_boost,
            "style": style,
            "use_speaker_boost": speaker_boost
        }
    }

    def make_request():
        response = requests.post(url, headers=headers, json=data, stream=True)
        audio_data = b"".join(response.iter_content(chunk_size=CHUNK_SIZE))
        audio_segment = AudioSegment.from_mp3(io.BytesIO(audio_data))
        wav_buffer = io.BytesIO()
        audio_segment.export(wav_buffer, format="wav")
        return wav_buffer.getvalue()

    return await asyncio.get_event_loop().run_in_executor(None, make_request)
```

## Provider Pattern

```python
@dataclass
class ProviderConfig:
    name: str
    settings: Dict[str, Any]

class ExampleProvider(Interface):
    def __init__(self, config: ProviderConfig):
        self._config = config  # Direct attribute access
        self._initialize()

# Registration
provider_config = self.config.module.providers[provider_name]
provider = ProviderClass(provider_config)
self.registry.register_provider(Interface, provider)
```

## Subprocess Execution

```python
# For shell commands
cmd = f'tool --input "{input_file}" --output "{output_dir}"'
process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, text=True)

# For direct execution
cmd = ["tool", "--input", input_file, "--output", output_dir]
process = subprocess.Popen(cmd, shell=False, stdout=subprocess.PIPE)

# Async execution
process = await asyncio.create_subprocess_exec(*cmd,
    stdout=asyncio.subprocess.PIPE)
stdout, stderr = await process.communicate()
```

## Pipeline Management

```python
def _start_pipeline(self):
    self.regular_mode.setEnabled(False)
    self.signals.disconnect()
    self.signals.connect(self._pipeline_handler,
                        type=Qt.ConnectionType.UniqueConnection)

def _end_pipeline(self):
    self._cleanup_pipeline_connections()
    self.regular_mode.setEnabled(True)
    self.signals.connect(self._regular_handler)
```

## Critical Rules

MUST:

- Use device's native sample rate
- Process all buffered data
- Use direct attribute config access
- Follow provider lifecycle
- Clean up all resources
- Log all operations
- Handle all errors
- Maintain thread safety
- Use proper async patterns
- Follow event architecture
- Convert ElevenLabs MP3 to WAV
- Run API requests in thread pool
- Quote shell command paths
- Handle subprocess streams properly

NEVER:

- Hardcode sample rates
- Skip buffer processing
- Use .get() on AppConfig
- Mix sync/async patterns
- Leave resources uncleaned
- Assume API availability
- Create duplicate windows
- Leave connections dangling
- Use SDK high-level functions
- Skip stream handling
- Mix bytes/text mode
- Leave processes running

## Directory Structure

- recordings/ - Temp audio
- reference_audio/ - TTS refs
- resources/audio/ - App assets

## Logging Format

- === State changes
- > > > Operations
- !!! Errors

## Config Format

```yaml
module_name:
  provider: name
  providers:
    provider_name:
      setting1: value1
      voice_settings:
        stability: 0.5
        similarity_boost: 0.8
        style: 0.0
        use_speaker_boost: true
```

## Documentation URLs

- PyQt6: https://doc.qt.io/qtforpython-6/
- ElevenLabs: https://docs.elevenlabs.io/
- PyAudio: https://people.csail.mit.edu/hubert/pyaudio/docs/
- Anthropic: https://docs.anthropic.com/claude/
- OpenAI: https://platform.openai.com/docs
- Deepgram: https://developers.deepgram.com/docs/
